# -*- coding: utf-8 -*-
"""PredictSaham_v3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19kLj1WFl2QDwakiWF_gD-6FSCF_CSBzE

**Library & Package**
"""

!pip install --upgrade quandl

!pip install -U scikit-learn

import sklearn

sklearn.__version__

# Libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import quandl

"""**Pengolahan Data**"""

data = pd.read_csv('Sahambaru.csv')

data.head()

data.tail()

from datetime import datetime as dt

# A variable for predicting 'n' days out into the future
data_prediksi = data.iloc[:314]
forecast_out = 4 #'n=30' days

# newdate = {'Date': ['4/01/2021', '11/01/2021', '18/01/2021', '25/01/2021']}
newdate = data_prediksi.iloc[-forecast_out:,0:1]
nwdate = pd.DataFrame(newdate)

weeklydate = pd.to_datetime(nwdate.Date)
weeklydate = weeklydate.dt.strftime("%d-%m-%Y")
weeklydate = pd.to_datetime(weeklydate)
weeklydate = np.array(weeklydate)
weeklydate

return_weeklydate = pd.to_datetime(data.Date)
return_weeklydate = return_weeklydate.dt.strftime("%d-%m-%Y")
return_weeklydate = pd.to_datetime(return_weeklydate)
return_weeklydate

"""**Return Saham**"""

def return_saham(datax, date):

  return_saham = pd.DataFrame(date)
  cum_returns_saham = pd.DataFrame(date)

  for i in range(1, len(datax.columns)):
    
    saham = datax.columns[i]
    weekly_returns = datax[saham].pct_change()
    cum_returns = (weekly_returns + 1).cumprod()
    return_saham[saham] = weekly_returns
    cum_returns_saham[saham] = cum_returns
  
  return return_saham, cum_returns_saham

return_saham, cum_return_shm = return_saham(data, return_weeklydate)

return_saham.head()

return_saham.tail()

cum_return_shm.head()

cum_return_shm.tail()

"""**Visualisasi Data Hasil Return**"""

import matplotlib.ticker

for i in range(1, len(return_saham.columns)):
  
  saham = data.columns[i]
  plt.figure(figsize=(16,8))
  plt.title(str(saham)+" weekly return data")
  plt.grid(True,  which='major', color='#666666', linestyle='-')
  plt.plot(return_weeklydate, return_saham[saham])
  plt.xlabel('Year')
  plt.ylabel('Return Values')
  plt.minorticks_on()
  plt.xticks(rotation = 50)
  plt.gcf().autofmt_xdate()
  plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.3)
  # plt.savefig(str(saham)+" weekly return data")
  plt.show()

for i in range(1, len(cum_return_shm.columns)):
  
  saham = data.columns[i]
  plt.figure(figsize=(16,8))
  plt.title(str(saham)+" weekly cumulative return data")
  plt.grid(True,  which='major', color='#666666', linestyle='-')
  plt.plot(return_weeklydate, cum_return_shm[saham])
  plt.xlabel('Year')
  plt.ylabel('Growth of Investment')
  plt.minorticks_on()
  plt.xticks(rotation = 50)
  plt.gcf().autofmt_xdate()
  plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.3)
  # plt.savefig(str(saham)+" weekly cumulative return data")
  plt.show()

plt.figure(figsize=(16,8))
plt.title("Variance weekly cumulative return saham")
plt.grid(True,  which='major', color='#666666', linestyle='-')
plt.plot(return_weeklydate, cum_return_shm['ACES'], label = "ACES")
plt.plot(return_weeklydate, cum_return_shm['ADRO'], label = "ADRO") 
plt.plot(return_weeklydate, cum_return_shm['BBRI'], label = "BBRI")
plt.plot(return_weeklydate, cum_return_shm['MNCN'], label = "MNCN")
plt.plot(return_weeklydate, cum_return_shm['TLKM'], label = "TLKM")
plt.ylim(0,4,0.5)
plt.xlabel('Year')
plt.ylabel('Growth of Investment')
plt.minorticks_on()
plt.xticks(rotation = 50)
plt.gcf().autofmt_xdate()
plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.3)
plt.legend()
# plt.savefig("Variance weekly cumulative return saham")
plt.show()

"""**Prediksi Saham**"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

target_saham = pd.DataFrame()
# predict_saham = pd.DataFrame(weeklydate, columns=['Date'])
predict_saham = pd.DataFrame()
confidence_predict_saham = pd.DataFrame(index=['confidence'])

modelRF = RandomForestRegressor(n_estimators=160, random_state=2)

stack_target_saham = pd.DataFrame()
stack_predict_saham = pd.DataFrame()
stack_confidence_predict_saham = pd.DataFrame()

for l in range(1, (forecast_out // 4) + 1):
  
  stack = 4
  stack_idx = (len(data_prediksi) - forecast_out) + (l * stack)
  stack_predict = data_prediksi.iloc[:stack_idx,:]

  for i in range(1, len(data_prediksi.columns)):
  
    saham = data_prediksi.columns[i]
  
    weekly_predict = pd.DataFrame(stack_predict[['Date',saham]])
    weekly_predict['Prediction'] = stack_predict[[saham]].shift(-stack)
  
    ### Create the independent data set (X)  #######
    # Convert the dataframe to a numpy array
    X = np.array(weekly_predict.drop(['Date','Prediction'],1))
    # Remove the last 'n' rows
    X = X[:-stack]

    ### Create the dependent data set (y)  #####
    # Convert the dataframe to a numpy array 
    y = np.array(weekly_predict['Prediction'])
    # Get all of the y values except the last 'n' rows
    y = y[:-stack]

    # Split the data into 80% training and 20% testing
    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    # Train Random Forest model 
    modelRF.fit(x_train,y_train)

    # Now test the model as return score coefficient of Random Forest
    # Best possible score is 1.0
    confidenceR = modelRF.score(x_test, y_test)

    # Set x_forecast equal to the last 30 rows of the original data set from Adj. Close column
    x_forecast = np.array(weekly_predict.drop(['Date', 'Prediction'],1))[-stack:]

    # Prediction Model 
    prediction_RF = modelRF.predict(x_forecast)
  
    target_saham[saham] = y[-stack:]
    predict_saham[saham] = prediction_RF
    confidence_predict_saham[saham] = confidenceR

  stack_target_saham = stack_target_saham.append(target_saham, ignore_index=True)
  stack_predict_saham = stack_predict_saham.append(predict_saham, ignore_index=True)
  stack_confidence_predict_saham = stack_confidence_predict_saham.append(confidence_predict_saham, ignore_index=True)

# "Dates"
apply_date = np.array(data_prediksi.iloc[-forecast_out:,:1])
apply_date = pd.DataFrame(apply_date, columns=['Date'])
target_saham = apply_date.join(stack_target_saham)
predict_saham = apply_date.join(stack_predict_saham)

target_saham

predict_saham

# Confidences RF Regression / execution
stack_confidence_predict_saham

# Predicted data scaling from 0 to 1 (there is a zero value)
scaling_data = predict_saham.iloc[:,1:].apply(lambda x: (x - x.min()) / (x.max() - x.min()))
scaling_data

# Scaling data using StandardScaler (is not a scaling from 0 to 1)
from sklearn.preprocessing import StandardScaler

# men-scaling hasil prediksi
scaling = StandardScaler()
scaling_predict = scaling.fit_transform(predict_saham.iloc[:,1:])
scaling_predict = pd.DataFrame(scaling_predict)
scaling_predict

# Please choose which scaling you want to use!
scaling_predict_saham = pd.DataFrame(predict_saham['Date'])

for i in range(len(scaling_predict.columns)):
  saham = data.columns[i+1]
  scaling_predict_saham[saham] = scaling_predict[i]

scaling_predict_saham

"""**Visualisasi Data Hasil Prediksi**"""

for i in range(1, len(predict_saham.columns)):
  
  saham = data.columns[i]
  plt.figure(figsize=(12,6))
  
  xlabels = ('Jan', 'Feb', 'Mar', 'Apr', 'Mei')
  xpos = np.array([0,1,2,3])

  plt.title(str(saham)+" stock price prediction for the next 4 weeks")
  plt.grid(True,  which='major', color='#666666', linestyle='-')
  plt.plot(target_saham[saham], label = "Real Prices")
  plt.plot(predict_saham[saham], label = "Prediction Prices")
  plt.xlabel('Month')
  plt.ylabel('Price Values')
  plt.xticks(xpos, xlabels)
  plt.minorticks_on()
  plt.gcf().autofmt_xdate()
  plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.3)
  plt.legend()
  # plt.savefig(str(saham)+" stock price prediction for the next 4 weeks")
  plt.show()

for i in range(1, len(predict_saham.columns)):
  for l in range(0,1):

    saham = data.columns[i]
    plt.figure(figsize=(12,6))
  
    stack = 4
    first = stack * l
    second = stack * (l+1)
    target_stack = target_saham.iloc[first:second,:]
    predict_stack = predict_saham.iloc[first:second,:] 

    target_stacks = pd.DataFrame()
    predict_stacks = pd.DataFrame()
    target_stacks = target_stacks.append(target_stack, ignore_index=True)    
    predict_stacks = predict_stacks.append(predict_stack, ignore_index=True)

    xlabels = ('Minggu-1', 'Minggu-2', 'Minggu-3', 'Minggu-4')
    xpos = np.arange(len(xlabels))
  
    plt.title(str(saham)+" stock price prediction month "+str(l+1)+" for the next 4 weeks")
    plt.grid(True,  which='major', color='#666666', linestyle='-')
    plt.plot(target_stacks[saham], label="Real Prices")
    plt.plot(predict_stacks[saham], label="Prediction Prices")
    plt.xlabel('Week')
    plt.ylabel('Price Values')
    plt.minorticks_on()
    plt.xticks(xpos, xlabels)
    plt.gcf().autofmt_xdate()
    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.3)
    # plt.savefig(str(saham)+" stock price prediction month "+str(l+1)+" for the next 4 weeks")
    plt.show()

"""**Prediksi *Mean Absolute Precentage Error* (MAPE)**"""

# Looking for the mape value based on the stock prediction results
mape_predict = pd.DataFrame()
mape_predict_saham = pd.DataFrame()

for l in range(0, (forecast_out // 4)):

  mape_stack = 4
  mape_first_idx = mape_stack * l
  mape_last_idx = mape_stack * (l + 1)
  target_data = target_saham.iloc[mape_first_idx:mape_last_idx,:]
  predict_data = predict_saham.iloc[mape_first_idx:mape_last_idx,:]

  for i in range(1, len(predict_saham.columns)):
  
    saham = data_prediksi.columns[i]
    target, predict = np.array(target_data[saham]), np.array(predict_data[saham]) 
    mape_manual = np.mean(np.abs((target - predict) / target))
    mape_manual = [mape_manual * 100]
    mape_predict[saham] = mape_manual

  mape_predict_saham = mape_predict_saham.append(mape_predict, ignore_index=True)

# The best value is close to zero
mape_predict_saham

"""**Return Hasil Prediksi**"""

data_hsl_predict = data_prediksi[:310]
data_hsl_predict = data_hsl_predict.append(predict_saham, ignore_index=True)

data_hsl_predict.tail()

return_hsl_weeklydate = pd.to_datetime(data_hsl_predict.Date)
return_hsl_weeklydate = return_hsl_weeklydate.dt.strftime("%d-%m-%Y")
return_hsl_weeklydate = pd.to_datetime(return_hsl_weeklydate)
return_hsl_weeklydate

data_hsl_predict

return_hsl_saham = pd.DataFrame(return_hsl_weeklydate)
cum_returns_hsl_saham = pd.DataFrame(return_hsl_weeklydate)

for i in range(1, len(data_hsl_predict.columns)):
    
  saham = data_hsl_predict.columns[i]
  weekly_returns = data_hsl_predict[saham].pct_change()
  cum_returns = (weekly_returns + 1).cumprod()
  return_hsl_saham[saham] = weekly_returns
  cum_returns_hsl_saham[saham] = cum_returns

return_hsl_saham

cum_returns_hsl_saham.tail()

cum_return_shm[310:314]

"""**Optimasi Portofolio**"""

# CQ-1 Covariance Matrix (Return 2018/2019)
dt_return = return_saham.iloc[1:314,1:]
return_ori = np.array([])
return_cmx = np.array([])  

n_saham = np.array(['CPIN','BBTN'])
setindx = 0

for i in n_saham:
  return_cov = dt_return[i]
  # print(return_cov)
  return_cov = np.array(return_cov)
  return_cov = return_cov[-setindx:]
  # print(return_cov)
  return_ori = np.append(return_ori, return_cov)
  return_cmx = np.append(return_cmx, np.cov(return_cov))
  print(return_cmx) 
# cuqu1 = np.sum(return_cmx)
# cuqu1

# CQ-2 Retrun Prediksi 
dt_return_predict = return_hsl_saham.iloc[1:314,1:]
return_predict = np.array([])
cuqu2 = np.array([])  

for i in n_saham:
  return_pred = dt_return_predict[i]
  return_pred = np.array(return_pred)
  return_pred = return_pred[-setindx:]
  return_predict = np.append(return_predict, return_pred)
  cuqu2 = np.append(cuqu2, np.cov(return_pred))

cuqu2 = np.sum(cuqu2)
cuqu2

# CQ-3 Return Sebenarnya - Return Predict
return_cq3 = np.array([])

for i in n_saham:
  dt_ori_cq3 = dt_return[i]
  dt_ori_cq3 = np.array(dt_ori_cq3)
  dt_ori_cq3 = dt_ori_cq3[-setindx:]

  dt_predict_cq3 = dt_return_predict[i]                                    
  dt_predict_cq3 = np.array(dt_predict_cq3)
  dt_predict_cq3 = dt_predict_cq3[-setindx:]

  for j in range(len(dt_predict_cq3)):
    return_cq3 = np.append(return_cq3, (dt_ori_cq3[j] - dt_predict_cq3[j]))

cuqu3 = np.sum(return_cq3)
cuqu3

# Optimasi Portofolio
optimasi_portofolio = np.array([])
optimasi_portofolio = np.append(optimasi_portofolio, cuqu1)
optimasi_portofolio = np.append(optimasi_portofolio, cuqu2)
optimasi_portofolio = np.append(optimasi_portofolio, cuqu3)

optms_porto = optimasi_portofolio[0]

for i in range(1,len(optimasi_portofolio)):
  optms_porto -= optimasi_portofolio[i]

print("Optimasi Portofolio :")
print("->",optms_porto)
print("->",round(optms_porto*100,2),"%")

#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#

mape_predict.to_csv('Nilai_Mape.csv', index=False)
target_saham.to_csv('Data_Target_Saham.csv', index=False)
predict_saham.to_csv('Data_Prediksi_Saham.csv', index=False)
scaling_predict_saham.to_csv('Data_Scaling_Prediksi_Saham.csv', index=False)
confidence_predict_saham.to_csv('Confidence_Prediksi_Saham.csv', index=False)

#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#